{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32c4597c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from delta import configure_spark_with_delta_pip\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "builder = (\n",
    "    SparkSession.builder.appName(\"ML Project\")\n",
    "    .config(\"spark.driver.memory\", \"16g\")\n",
    ")\n",
    "\n",
    "spark = configure_spark_with_delta_pip(builder).getOrCreate()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f59321e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8 CSV files.\n",
      "✅ Loaded Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv with 225745 rows\n",
      "✅ Loaded Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv with 286467 rows\n",
      "✅ Loaded Friday-WorkingHours-Morning.pcap_ISCX.csv with 191033 rows\n",
      "✅ Loaded Monday-WorkingHours.pcap_ISCX.csv with 529918 rows\n",
      "✅ Loaded Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX.csv with 288602 rows\n",
      "✅ Loaded Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv with 170366 rows\n",
      "✅ Loaded Tuesday-WorkingHours.pcap_ISCX.csv with 445909 rows\n",
      "✅ Loaded Wednesday-workingHours.pcap_ISCX.csv with 692703 rows\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# My Spark session\n",
    "spark\n",
    "\n",
    "# Path to my folder with CSV files\n",
    "folder = r\"C:\\Users\\Ranveer Verma\\Desktop\\ML Project\"\n",
    "\n",
    "# Getting all CSV filenames\n",
    "csv_files = [f for f in os.listdir(folder) if f.endswith(\".csv\")]\n",
    "print(f\"Found {len(csv_files)} CSV files.\")\n",
    "\n",
    "# Loading each CSV into a DataFrame\n",
    "dfs = []\n",
    "for file in csv_files:\n",
    "    path = os.path.join(folder, file)\n",
    "    df = spark.read.option(\"header\", True).option(\"inferSchema\", True).csv(path)\n",
    "    dfs.append(df)\n",
    "    print(f\"✅ Loaded {file} with {df.count()} rows\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081faab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Combined all CSV files into a single DataFrame\n",
      "Total rows: 2830743\n"
     ]
    }
   ],
   "source": [
    "# Combining all DataFrames\n",
    "if dfs:\n",
    "    combined_df = dfs[0]\n",
    "    for df in dfs[1:]:\n",
    "        combined_df = combined_df.unionByName(df, allowMissingColumns=True)\n",
    "    print(\"✅ Combined all CSV files into a single DataFrame\")\n",
    "    print(f\"Total rows: {combined_df.count()}\")\n",
    "else:\n",
    "    print(\"⚠️ No CSV files found\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9003585",
   "metadata": {},
   "source": [
    "**PREPROCESSING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e550f744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ df_filled created successfully\n",
      "root\n",
      " |-- Destination Port: integer (nullable = true)\n",
      " |-- Flow Duration: integer (nullable = true)\n",
      " |-- Total Fwd Packets: integer (nullable = true)\n",
      " |-- Total Backward Packets: integer (nullable = true)\n",
      " |-- Total Length of Fwd Packets: integer (nullable = true)\n",
      " |-- Total Length of Bwd Packets: integer (nullable = true)\n",
      " |-- Fwd Packet Length Max: integer (nullable = true)\n",
      " |-- Fwd Packet Length Min: integer (nullable = true)\n",
      " |-- Fwd Packet Length Mean: double (nullable = true)\n",
      " |-- Fwd Packet Length Std: double (nullable = true)\n",
      " |-- Bwd Packet Length Max: integer (nullable = true)\n",
      " |-- Bwd Packet Length Min: integer (nullable = true)\n",
      " |-- Bwd Packet Length Mean: double (nullable = true)\n",
      " |-- Bwd Packet Length Std: double (nullable = true)\n",
      " |-- Flow Bytes/s: double (nullable = true)\n",
      " |-- Flow Packets/s: double (nullable = true)\n",
      " |-- Flow IAT Mean: double (nullable = true)\n",
      " |-- Flow IAT Std: double (nullable = true)\n",
      " |-- Flow IAT Max: integer (nullable = true)\n",
      " |-- Flow IAT Min: integer (nullable = true)\n",
      " |-- Fwd IAT Total: integer (nullable = true)\n",
      " |-- Fwd IAT Mean: double (nullable = true)\n",
      " |-- Fwd IAT Std: double (nullable = true)\n",
      " |-- Fwd IAT Max: integer (nullable = true)\n",
      " |-- Fwd IAT Min: integer (nullable = true)\n",
      " |-- Bwd IAT Total: integer (nullable = true)\n",
      " |-- Bwd IAT Mean: double (nullable = true)\n",
      " |-- Bwd IAT Std: double (nullable = true)\n",
      " |-- Bwd IAT Max: integer (nullable = true)\n",
      " |-- Bwd IAT Min: integer (nullable = true)\n",
      " |-- Fwd PSH Flags: integer (nullable = true)\n",
      " |-- Bwd PSH Flags: integer (nullable = true)\n",
      " |-- Fwd URG Flags: integer (nullable = true)\n",
      " |-- Bwd URG Flags: integer (nullable = true)\n",
      " |-- Fwd Header Length34: long (nullable = true)\n",
      " |-- Bwd Header Length: integer (nullable = true)\n",
      " |-- Fwd Packets/s: double (nullable = true)\n",
      " |-- Bwd Packets/s: double (nullable = true)\n",
      " |-- Min Packet Length: integer (nullable = true)\n",
      " |-- Max Packet Length: integer (nullable = true)\n",
      " |-- Packet Length Mean: double (nullable = true)\n",
      " |-- Packet Length Std: double (nullable = true)\n",
      " |-- Packet Length Variance: double (nullable = true)\n",
      " |-- FIN Flag Count: integer (nullable = true)\n",
      " |-- SYN Flag Count: integer (nullable = true)\n",
      " |-- RST Flag Count: integer (nullable = true)\n",
      " |-- PSH Flag Count: integer (nullable = true)\n",
      " |-- ACK Flag Count: integer (nullable = true)\n",
      " |-- URG Flag Count: integer (nullable = true)\n",
      " |-- CWE Flag Count: integer (nullable = true)\n",
      " |-- ECE Flag Count: integer (nullable = true)\n",
      " |-- Down/Up Ratio: integer (nullable = true)\n",
      " |-- Average Packet Size: double (nullable = true)\n",
      " |-- Avg Fwd Segment Size: double (nullable = true)\n",
      " |-- Avg Bwd Segment Size: double (nullable = true)\n",
      " |-- Fwd Header Length55: long (nullable = true)\n",
      " |-- Fwd Avg Bytes/Bulk: integer (nullable = true)\n",
      " |-- Fwd Avg Packets/Bulk: integer (nullable = true)\n",
      " |-- Fwd Avg Bulk Rate: integer (nullable = true)\n",
      " |-- Bwd Avg Bytes/Bulk: integer (nullable = true)\n",
      " |-- Bwd Avg Packets/Bulk: integer (nullable = true)\n",
      " |-- Bwd Avg Bulk Rate: integer (nullable = true)\n",
      " |-- Subflow Fwd Packets: integer (nullable = true)\n",
      " |-- Subflow Fwd Bytes: integer (nullable = true)\n",
      " |-- Subflow Bwd Packets: integer (nullable = true)\n",
      " |-- Subflow Bwd Bytes: integer (nullable = true)\n",
      " |-- Init_Win_bytes_forward: integer (nullable = true)\n",
      " |-- Init_Win_bytes_backward: integer (nullable = true)\n",
      " |-- act_data_pkt_fwd: integer (nullable = true)\n",
      " |-- min_seg_size_forward: integer (nullable = true)\n",
      " |-- Active Mean: double (nullable = true)\n",
      " |-- Active Std: double (nullable = true)\n",
      " |-- Active Max: integer (nullable = true)\n",
      " |-- Active Min: integer (nullable = true)\n",
      " |-- Idle Mean: double (nullable = true)\n",
      " |-- Idle Std: double (nullable = true)\n",
      " |-- Idle Max: integer (nullable = true)\n",
      " |-- Idle Min: integer (nullable = true)\n",
      " |-- Label: string (nullable = true)\n",
      "\n",
      "+----------------+-------------+-----------------+----------------------+---------------------------+---------------------------+---------------------+---------------------+----------------------+---------------------+---------------------+---------------------+----------------------+---------------------+------------+--------------+-------------+------------+------------+------------+-------------+------------+-----------+-----------+-----------+-------------+------------+-----------+-----------+-----------+-------------+-------------+-------------+-------------+-------------------+-----------------+-------------+-------------+-----------------+-----------------+------------------+-----------------+----------------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+-------------+-------------------+--------------------+--------------------+-------------------+------------------+--------------------+-----------------+------------------+--------------------+-----------------+-------------------+-----------------+-------------------+-----------------+----------------------+-----------------------+----------------+--------------------+-----------+----------+----------+----------+---------+--------+--------+--------+------+\n",
      "|Destination Port|Flow Duration|Total Fwd Packets|Total Backward Packets|Total Length of Fwd Packets|Total Length of Bwd Packets|Fwd Packet Length Max|Fwd Packet Length Min|Fwd Packet Length Mean|Fwd Packet Length Std|Bwd Packet Length Max|Bwd Packet Length Min|Bwd Packet Length Mean|Bwd Packet Length Std|Flow Bytes/s|Flow Packets/s|Flow IAT Mean|Flow IAT Std|Flow IAT Max|Flow IAT Min|Fwd IAT Total|Fwd IAT Mean|Fwd IAT Std|Fwd IAT Max|Fwd IAT Min|Bwd IAT Total|Bwd IAT Mean|Bwd IAT Std|Bwd IAT Max|Bwd IAT Min|Fwd PSH Flags|Bwd PSH Flags|Fwd URG Flags|Bwd URG Flags|Fwd Header Length34|Bwd Header Length|Fwd Packets/s|Bwd Packets/s|Min Packet Length|Max Packet Length|Packet Length Mean|Packet Length Std|Packet Length Variance|FIN Flag Count|SYN Flag Count|RST Flag Count|PSH Flag Count|ACK Flag Count|URG Flag Count|CWE Flag Count|ECE Flag Count|Down/Up Ratio|Average Packet Size|Avg Fwd Segment Size|Avg Bwd Segment Size|Fwd Header Length55|Fwd Avg Bytes/Bulk|Fwd Avg Packets/Bulk|Fwd Avg Bulk Rate|Bwd Avg Bytes/Bulk|Bwd Avg Packets/Bulk|Bwd Avg Bulk Rate|Subflow Fwd Packets|Subflow Fwd Bytes|Subflow Bwd Packets|Subflow Bwd Bytes|Init_Win_bytes_forward|Init_Win_bytes_backward|act_data_pkt_fwd|min_seg_size_forward|Active Mean|Active Std|Active Max|Active Min|Idle Mean|Idle Std|Idle Max|Idle Min| Label|\n",
      "+----------------+-------------+-----------------+----------------------+---------------------------+---------------------------+---------------------+---------------------+----------------------+---------------------+---------------------+---------------------+----------------------+---------------------+------------+--------------+-------------+------------+------------+------------+-------------+------------+-----------+-----------+-----------+-------------+------------+-----------+-----------+-----------+-------------+-------------+-------------+-------------+-------------------+-----------------+-------------+-------------+-----------------+-----------------+------------------+-----------------+----------------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+-------------+-------------------+--------------------+--------------------+-------------------+------------------+--------------------+-----------------+------------------+--------------------+-----------------+-------------------+-----------------+-------------------+-----------------+----------------------+-----------------------+----------------+--------------------+-----------+----------+----------+----------+---------+--------+--------+--------+------+\n",
      "|           54865|            3|                2|                     0|                         12|                          0|                    6|                    6|                   6.0|                  0.0|                    0|                    0|                   0.0|                  0.0|   4000000.0|   666666.6667|          3.0|         0.0|           3|           3|            3|         3.0|        0.0|          3|          3|            0|         0.0|        0.0|          0|          0|            0|            0|            0|            0|                 40|                0|  666666.6667|          0.0|                6|                6|               6.0|              0.0|                   0.0|             0|             0|             0|             0|             1|             0|             0|             0|            0|                9.0|                 6.0|                 0.0|                 40|                 0|                   0|                0|                 0|                   0|                0|                  2|               12|                  0|                0|                    33|                     -1|               1|                  20|        0.0|       0.0|         0|         0|      0.0|     0.0|       0|       0|BENIGN|\n",
      "|           55054|          109|                1|                     1|                          6|                          6|                    6|                    6|                   6.0|                  0.0|                    6|                    6|                   6.0|                  0.0| 110091.7431|   18348.62385|        109.0|         0.0|         109|         109|            0|         0.0|        0.0|          0|          0|            0|         0.0|        0.0|          0|          0|            0|            0|            0|            0|                 20|               20|  9174.311927|  9174.311927|                6|                6|               6.0|              0.0|                   0.0|             0|             0|             0|             0|             1|             1|             0|             0|            1|                9.0|                 6.0|                 6.0|                 20|                 0|                   0|                0|                 0|                   0|                0|                  1|                6|                  1|                6|                    29|                    256|               0|                  20|        0.0|       0.0|         0|         0|      0.0|     0.0|       0|       0|BENIGN|\n",
      "|           55055|           52|                1|                     1|                          6|                          6|                    6|                    6|                   6.0|                  0.0|                    6|                    6|                   6.0|                  0.0| 230769.2308|   38461.53846|         52.0|         0.0|          52|          52|            0|         0.0|        0.0|          0|          0|            0|         0.0|        0.0|          0|          0|            0|            0|            0|            0|                 20|               20|  19230.76923|  19230.76923|                6|                6|               6.0|              0.0|                   0.0|             0|             0|             0|             0|             1|             1|             0|             0|            1|                9.0|                 6.0|                 6.0|                 20|                 0|                   0|                0|                 0|                   0|                0|                  1|                6|                  1|                6|                    29|                    256|               0|                  20|        0.0|       0.0|         0|         0|      0.0|     0.0|       0|       0|BENIGN|\n",
      "|           46236|           34|                1|                     1|                          6|                          6|                    6|                    6|                   6.0|                  0.0|                    6|                    6|                   6.0|                  0.0| 352941.1765|   58823.52941|         34.0|         0.0|          34|          34|            0|         0.0|        0.0|          0|          0|            0|         0.0|        0.0|          0|          0|            0|            0|            0|            0|                 20|               20|  29411.76471|  29411.76471|                6|                6|               6.0|              0.0|                   0.0|             0|             0|             0|             0|             1|             1|             0|             0|            1|                9.0|                 6.0|                 6.0|                 20|                 0|                   0|                0|                 0|                   0|                0|                  1|                6|                  1|                6|                    31|                    329|               0|                  20|        0.0|       0.0|         0|         0|      0.0|     0.0|       0|       0|BENIGN|\n",
      "|           54863|            3|                2|                     0|                         12|                          0|                    6|                    6|                   6.0|                  0.0|                    0|                    0|                   0.0|                  0.0|   4000000.0|   666666.6667|          3.0|         0.0|           3|           3|            3|         3.0|        0.0|          3|          3|            0|         0.0|        0.0|          0|          0|            0|            0|            0|            0|                 40|                0|  666666.6667|          0.0|                6|                6|               6.0|              0.0|                   0.0|             0|             0|             0|             0|             1|             0|             0|             0|            0|                9.0|                 6.0|                 0.0|                 40|                 0|                   0|                0|                 0|                   0|                0|                  2|               12|                  0|                0|                    32|                     -1|               1|                  20|        0.0|       0.0|         0|         0|      0.0|     0.0|       0|       0|BENIGN|\n",
      "+----------------+-------------+-----------------+----------------------+---------------------------+---------------------------+---------------------+---------------------+----------------------+---------------------+---------------------+---------------------+----------------------+---------------------+------------+--------------+-------------+------------+------------+------------+-------------+------------+-----------+-----------+-----------+-------------+------------+-----------+-----------+-----------+-------------+-------------+-------------+-------------+-------------------+-----------------+-------------+-------------+-----------------+-----------------+------------------+-----------------+----------------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+-------------+-------------------+--------------------+--------------------+-------------------+------------------+--------------------+-----------------+------------------+--------------------+-----------------+-------------------+-----------------+-------------------+-----------------+----------------------+-----------------------+----------------+--------------------+-----------+----------+----------+----------+---------+--------+--------+--------+------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, trim\n",
    "\n",
    "# 1️⃣ Remove leading/trailing spaces from all column names\n",
    "combined_df = combined_df.toDF(*[c.strip() for c in combined_df.columns])\n",
    "\n",
    "# 2️⃣ Trim whitespace from the Label column (important for CIC-IDS)\n",
    "df_filled = combined_df.withColumn(\"Label\", trim(col(\"Label\")))\n",
    "\n",
    "print(\"✅ df_filled created successfully\")\n",
    "df_filled.printSchema()\n",
    "df_filled.show(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41bb88a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import row_number\n",
    "\n",
    "distinct_labels = df_filled.select(\"Label\").distinct()\n",
    "window = Window.orderBy(\"Label\")\n",
    "label_mapping = distinct_labels.withColumn(\"label_index\", row_number().over(window) - 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3d56015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+\n",
      "| Label|label_index|\n",
      "+------+-----------+\n",
      "|BENIGN|          0|\n",
      "|BENIGN|          0|\n",
      "|BENIGN|          0|\n",
      "|BENIGN|          0|\n",
      "|BENIGN|          0|\n",
      "+------+-----------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "df_indexed = df_filled.join(label_mapping, on=\"Label\", how=\"left\")\n",
    "df_indexed.select(\"Label\", \"label_index\").show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5746f3bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------+-----------+\n",
      "|Label                     |label_index|\n",
      "+--------------------------+-----------+\n",
      "|BENIGN                    |0          |\n",
      "|Bot                       |1          |\n",
      "|DDoS                      |2          |\n",
      "|DoS GoldenEye             |3          |\n",
      "|DoS Hulk                  |4          |\n",
      "|DoS Slowhttptest          |5          |\n",
      "|DoS slowloris             |6          |\n",
      "|FTP-Patator               |7          |\n",
      "|Heartbleed                |8          |\n",
      "|Infiltration              |9          |\n",
      "|PortScan                  |10         |\n",
      "|SSH-Patator               |11         |\n",
      "|Web Attack � Brute Force  |12         |\n",
      "|Web Attack � Sql Injection|13         |\n",
      "|Web Attack � XSS          |14         |\n",
      "+--------------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_indexed.select(\"Label\", \"label_index\").distinct().orderBy(\"label_index\").show(50, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c7fe5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import row_number\n",
    "\n",
    "distinct_labels = df_filled.select(\"Label\").distinct()\n",
    "window = Window.orderBy(\"Label\")\n",
    "label_mapping = distinct_labels.withColumn(\"label_index\", row_number().over(window) - 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9848a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Destination Port', 'Flow Duration', 'Total Fwd Packets', 'Total Backward Packets', 'Total Length of Fwd Packets', 'Total Length of Bwd Packets', 'Fwd Packet Length Max', 'Fwd Packet Length Min', 'Fwd Packet Length Mean', 'Fwd Packet Length Std']\n"
     ]
    }
   ],
   "source": [
    "# Get all numeric columns (excluding the label)\n",
    "numeric_cols = [col_name for col_name, dtype in df_indexed.dtypes if dtype in ('int', 'double', 'float')]\n",
    "\n",
    "# Showing first few numeric columns for verification\n",
    "print(numeric_cols[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c995f494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric columns after removing constants: ['Destination Port', 'Flow Duration', 'Total Fwd Packets', 'Total Backward Packets', 'Total Length of Fwd Packets', 'Total Length of Bwd Packets', 'Fwd Packet Length Max', 'Fwd Packet Length Min', 'Fwd Packet Length Mean', 'Fwd Packet Length Std']\n",
      "Numeric columns after removing zero-variance: ['Destination Port', 'Flow Duration', 'Total Fwd Packets', 'Total Backward Packets', 'Total Length of Fwd Packets', 'Total Length of Bwd Packets', 'Fwd Packet Length Max', 'Fwd Packet Length Min', 'Fwd Packet Length Mean', 'Fwd Packet Length Std']\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------+\n",
      "|scaled_features                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |label_index|\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------+\n",
      "|(68,[0,1,2,4,6,7,8,14,16,17,18,19,21,22,30,32,34,35,36,43,48,49,51,52,53,56,57,58,59],[3.0007713720523452,8.914312750303792E-8,0.0026678305789059596,0.0012007697859649045,0.00836604408047714,0.09943760518274626,0.032242262938486484,6.654918260611274E-7,1.226515335891565E-7,1.01685202531675E-6,8.935003661529252E-8,3.149367415039875E-7,1.2230342653501938E-7,3.4918491877049733E-7,1.8999795771655786E-6,2.6931986634250893,0.23773937623352398,0.0029582456256622637,0.019640483493777266,2.1512254743316914,0.0271198412833178,0.032242262938486484,1.8999795771655786E-6,0.0026678305789059596,0.0012023963465877675,0.0023014597235176187,-1.1824687434333851E-4,0.0015712754163188772,1.843336008472279E-5])                                                                                                                                                               |0          |\n",
      "|(68,[0,1,2,3,4,5,6,7,8,10,11,12,14,16,17,30,31,32,33,34,35,36,43,44,47,48,49,50,51,52,53,54,55,56,57,59],[3.011108486593818,3.2388669659437107E-6,0.0013339152894529798,0.0010026185700958519,6.003848929824522E-4,2.6512446104004263E-6,0.00836604408047714,0.09943760518274626,0.032242262938486484,0.0030826657245120086,0.08713002078552479,0.009913147607082635,2.417953634688763E-5,4.456339053739353E-6,3.694562358650859E-5,9.499897885827893E-7,1.3772122905145967E-5,0.037062366927608774,0.24046929715112336,0.23773937623352398,0.0029582456256622637,0.019640483493777266,2.1512254743316914,3.4133120336635057,1.4695250208013761,0.0271198412833178,0.032242262938486484,0.009913147607082314,9.499897885827893E-7,0.0013339152894529798,6.011981732938837E-4,0.0010026185700958519,2.651280656359722E-6,0.002022494908545786,0.03027119983189466,1.843336008472279E-5])  |0          |\n",
      "|(68,[0,1,2,3,4,5,6,7,8,10,11,12,14,16,17,30,31,32,33,34,35,36,43,44,47,48,49,50,51,52,53,54,55,56,57,59],[3.0111631803215504,1.5451475433859904E-6,0.0013339152894529798,0.0010026185700958519,6.003848929824522E-4,2.6512446104004263E-6,0.00836604408047714,0.09943760518274626,0.032242262938486484,0.0030826657245120086,0.08713002078552479,0.009913147607082635,1.1535191651726208E-5,2.1259599155453795E-6,1.7625435105490335E-5,9.499897885827893E-7,1.3772122905145967E-5,0.07768842297642409,0.5040606420634023,0.23773937623352398,0.0029582456256622637,0.019640483493777266,2.1512254743316914,3.4133120336635057,1.4695250208013761,0.0271198412833178,0.032242262938486484,0.009913147607082314,9.499897885827893E-7,0.0013339152894529798,6.011981732938837E-4,0.0010026185700958519,2.651280656359722E-6,0.002022494908545786,0.03027119983189466,1.843336008472279E-5])|0          |\n",
      "|(68,[0,1,2,3,4,5,6,7,8,10,11,12,14,16,17,30,31,32,33,34,35,36,43,44,47,48,49,50,51,52,53,54,55,56,57,59],[2.5288191954472294,1.010288778367763E-6,0.0013339152894529798,0.0010026185700958519,6.003848929824522E-4,2.6512446104004263E-6,0.00836604408047714,0.09943760518274626,0.032242262938486484,0.0030826657245120086,0.08713002078552479,0.009913147607082635,7.542240695359444E-6,1.3900507140104403E-6,1.1524322953589834E-5,9.499897885827893E-7,1.3772122905145967E-5,0.11881758810297695,0.7709162762357331,0.23773937623352398,0.0029582456256622637,0.019640483493777266,2.1512254743316914,3.4133120336635057,1.4695250208013761,0.0271198412833178,0.032242262938486484,0.009913147607082314,9.499897885827893E-7,0.0013339152894529798,6.011981732938837E-4,0.0010026185700958519,2.651280656359722E-6,0.0021619773160317024,0.03890322165895837,1.843336008472279E-5]) |0          |\n",
      "|(68,[0,1,2,4,6,7,8,14,16,17,18,19,21,22,30,32,34,35,36,43,48,49,51,52,53,56,57,58,59],[3.00066198459688,8.914312750303792E-8,0.0026678305789059596,0.0012007697859649045,0.00836604408047714,0.09943760518274626,0.032242262938486484,6.654918260611274E-7,1.226515335891565E-7,1.01685202531675E-6,8.935003661529252E-8,3.149367415039875E-7,1.2230342653501938E-7,3.4918491877049733E-7,1.8999795771655786E-6,2.6931986634250893,0.23773937623352398,0.0029582456256622637,0.019640483493777266,2.1512254743316914,0.0271198412833178,0.032242262938486484,1.8999795771655786E-6,0.0026678305789059596,0.0012023963465877675,0.0022317185197746605,-1.1824687434333851E-4,0.0015712754163188772,1.843336008472279E-5])                                                                                                                                                                 |0          |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------+\n",
      "only showing top 5 rows\n",
      "✅ Preprocessing complete. Data ready for ML!\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import IntegerType, DoubleType, FloatType, LongType\n",
    "from pyspark.sql.functions import col, isnan, when, count, expr\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Select numeric columns\n",
    "# -----------------------------\n",
    "numeric_cols = [\n",
    "    f.name for f in df_indexed.schema.fields\n",
    "    if isinstance(f.dataType, (IntegerType, DoubleType, FloatType, LongType))\n",
    "]\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Fill NaNs with 0\n",
    "# -----------------------------\n",
    "df_indexed = df_indexed.fillna(0, subset=numeric_cols)\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Remove constant columns\n",
    "# -----------------------------\n",
    "non_constant_cols = []\n",
    "for c in numeric_cols:\n",
    "    stats = df_indexed.agg(F.max(c).alias(\"max_val\"), F.min(c).alias(\"min_val\")).collect()[0]\n",
    "    if stats[\"max_val\"] != stats[\"min_val\"]:\n",
    "        non_constant_cols.append(c)\n",
    "numeric_cols = non_constant_cols\n",
    "print(\"Numeric columns after removing constants:\", numeric_cols[:10])\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Remove zero-variance columns\n",
    "# -----------------------------\n",
    "stddev_cols = [\n",
    "    (c, df_indexed.agg(F.stddev(c).alias(\"std\")).collect()[0][\"std\"])\n",
    "    for c in numeric_cols\n",
    "]\n",
    "non_zero_std_cols = [c for c, std in stddev_cols if std and std > 0]\n",
    "print(\"Numeric columns after removing zero-variance:\", non_zero_std_cols[:10])\n",
    "\n",
    "# Exclude label column\n",
    "feature_cols = [c for c in non_zero_std_cols if c != \"label_index\"]\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Assemble features\n",
    "# -----------------------------\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=feature_cols,\n",
    "    outputCol=\"features_vector\"\n",
    ")\n",
    "df_vector = assembler.transform(df_indexed)\n",
    "\n",
    "# -----------------------------\n",
    "# 6. Standardize features\n",
    "# -----------------------------\n",
    "scaler = StandardScaler(\n",
    "    inputCol=\"features_vector\",\n",
    "    outputCol=\"scaled_features\",\n",
    "    withMean=False,\n",
    "    withStd=True\n",
    ")\n",
    "scaler_model = scaler.fit(df_vector)\n",
    "df_scaled = scaler_model.transform(df_vector)\n",
    "\n",
    "# -----------------------------\n",
    "# 7. Quick look at final DataFrame that we get\n",
    "# -----------------------------\n",
    "df_scaled.select(\"scaled_features\", \"label_index\").show(5, truncate=False)\n",
    "\n",
    "print(\"✅ Preprocessing complete. Data ready for ML!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab851774",
   "metadata": {},
   "source": [
    "****TRAINING THE MODEL NOW****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf8c154",
   "metadata": {},
   "source": [
    "IMPLEMENTING LOGISTIC REGRESSION ON THE SAMPLE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf7ea275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled dataset count: 708271\n",
      "Train count: 567183, Test count: 141848\n",
      "✅ Test Accuracy on sample: 0.9254\n",
      "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------+----------+\n",
      "|scaled_features                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |label_index|prediction|\n",
      "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------+----------+\n",
      "|(68,[1,2,14,15,16,17,18,19,20,21,22,32,52,56,57],[5.992795318270895E-4,0.005335661157811919,0.0014912932387407011,0.0014467716292693672,8.243818410972506E-4,6.779013502111667E-7,6.006705128190732E-4,7.057382447741507E-4,0.0012076428287339043,8.220420975507104E-4,2.3278994584699821E-7,8.012292729046973E-4,0.005335661157811919,-6.974120374295814E-5,-1.1824687434333851E-4])                                                                                                                     |0          |0.0       |\n",
      "|(68,[1,2,14,15,16,17,18,19,20,21,22,32,52,56,57,60,62,63,64,66,67],[0.945225824468369,0.005335661157811919,2.35140445208265,2.2868876210907265,1.300106256045059,6.779013502111667E-7,0.9471103881221007,1.1127764866474226,1.908900741387402,1.2964163212712057,2.3278994584699821E-7,5.079847503356082E-7,0.005335661157811919,-6.974120374295814E-5,-1.1824687434333851E-4,3.0835649012666367E-6,1.9496503291642438E-6,3.4656502308085554E-6,1.3457424568055765,1.3050496875342608,1.3611021614049517])|0          |0.0       |\n",
      "|(68,[1,2,14,15,16,17,18,19,20,21,22,32,52,56,57,60,62,63,64,66,67],[0.946699954653511,0.005335661157811919,2.35140445208265,2.2868876210907265,1.304194640498031,6.779013502111667E-7,0.9500887226759438,1.1127764866474226,1.908900741387402,1.3004931021557062,2.3278994584699821E-7,5.071937538484018E-7,0.005335661157811919,-6.974120374295814E-5,-1.1824687434333851E-4,3.0835649012666367E-6,1.9496503291642438E-6,3.4656502308085554E-6,1.349974351323833,1.3091536173692742,1.365382356881068])  |0          |0.0       |\n",
      "|(68,[1,2,14,15,16,18,19,20,21,32,52,56,57,60,61,62,63,64,65,66,67],[3.186842442445421,0.1574020041554516,0.20334316991517923,0.26189910820188156,0.5028712877155417,3.1868179726120998,0.09622993526339109,0.21861126764804734,0.5014440487935795,4.4447534541225616E-6,0.1574020041554516,-6.974120374295814E-5,-1.1824687434333851E-4,5.5765430967971525,8.643718722424964,7.8709986571549955,1.7328251154042777E-6,0.31433903617785686,0.5009607557189405,0.5047833697066479,0.21401024462731238])     |0          |0.0       |\n",
      "|(68,[1,2,14,15,16,18,19,20,21,32,52,56,57,60,61,62,63,64,65,66,67],[3.3133724947669916,0.3895032645202701,0.08500258486508125,0.18193694331240434,0.4129268297501602,3.335734700304254,0.040226545313519615,0.1518656023023827,0.4117548693345653,1.057885952215293E-5,0.3895032645202701,-6.974120374295814E-5,-1.1824687434333851E-4,8.889382611841343,15.03908399263535,15.304755083939314,7.970995530859677E-5,0.3352431509640398,0.391386217260717,0.41449691333635325,0.2143852753549297])          |0          |0.0       |\n",
      "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------+----------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 1. Sample 700k rows from the dataset\n",
    "# -----------------------------\n",
    "sample_df = df_scaled.sample(withReplacement=False, fraction=0.25, seed=42)  \n",
    "print(f\"Sampled dataset count: {sample_df.count()}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Split into train and test sets\n",
    "# -----------------------------\n",
    "train_df, test_df = sample_df.randomSplit([0.8, 0.2], seed=42)\n",
    "print(f\"Train count: {train_df.count()}, Test count: {test_df.count()}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Training Logistic Regression on sample\n",
    "# -----------------------------\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "lr = LogisticRegression(\n",
    "    featuresCol=\"scaled_features\",\n",
    "    labelCol=\"label_index\",\n",
    "    maxIter=50,\n",
    "    regParam=0.01,\n",
    "    elasticNetParam=0.0\n",
    ")\n",
    "\n",
    "lr_model = lr.fit(train_df)\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Predictions and Evaluation\n",
    "# -----------------------------\n",
    "predictions = lr_model.transform(test_df)\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label_index\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"accuracy\"\n",
    ")\n",
    "\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(f\"✅ Test Accuracy on sample: {accuracy:.4f}\")\n",
    "\n",
    "#Showing the predictions\n",
    "predictions.select(\"scaled_features\", \"label_index\", \"prediction\").show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c18c924e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 0.851788351852596\n",
      "Precision: 0.9369\n",
      "Recall: 0.9801\n",
      "F1-score: 0.9172\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# -----------------------------\n",
    "# Binary Classification Evaluator\n",
    "# -----------------------------\n",
    "binary_evaluator = BinaryClassificationEvaluator(\n",
    "    labelCol=\"label_index\",\n",
    "    rawPredictionCol=\"prediction\",  \n",
    "    metricName=\"areaUnderROC\"        \n",
    ")\n",
    "roc_auc = binary_evaluator.evaluate(predictions)\n",
    "print(\"ROC-AUC:\", roc_auc)\n",
    "\n",
    "# -----------------------------\n",
    "# Multiclass Evaluator for precision, recall, f1\n",
    "# -----------------------------\n",
    "precision_eval = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label_index\", predictionCol=\"prediction\", metricName=\"precisionByLabel\"\n",
    ")\n",
    "recall_eval = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label_index\", predictionCol=\"prediction\", metricName=\"recallByLabel\"\n",
    ")\n",
    "f1_eval = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label_index\", predictionCol=\"prediction\", metricName=\"f1\"\n",
    ")\n",
    "\n",
    "precision = precision_eval.evaluate(predictions)\n",
    "recall = recall_eval.evaluate(predictions)\n",
    "f1 = f1_eval.evaluate(predictions)\n",
    "\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4394baf",
   "metadata": {},
   "source": [
    "IMPLEMENTING RANDOM FOREST ON THE SAMPLE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "164b6e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Random Forest Test Accuracy: 0.9959\n",
      "ROC-AUC: 0.9928\n",
      "Precision: 0.9952\n",
      "Recall: 0.9959\n",
      "F1-score: 0.9953\n",
      "+-----------+----------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|label_index|prediction|probability                                                                                                                                                                                                                                                |\n",
      "+-----------+----------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|0          |0.0       |[0.9071927683284616,0.0,0.013204180848055866,0.0021395518648095677,0.07595004403418132,1.0296084262192974E-4,2.043899891103443E-5,1.1989903305893229E-4,0.0,0.0,4.5240385307725997E-4,7.569195329987885E-5,4.3823671378903444E-4,0.0,3.0382352973367505E-4]|\n",
      "|0          |0.0       |[0.9343562340643728,0.0,0.003478022674809914,0.014434782608695653,0.04760874607617528,8.802816901408451E-5,2.6948325557163265E-6,0.0,0.0,0.0,1.8832391713747646E-5,7.280669821623589E-6,0.0,0.0,5.378512841199408E-6]                                      |\n",
      "|0          |0.0       |[0.9343562340643728,0.0,0.003478022674809914,0.014434782608695653,0.04760874607617528,8.802816901408451E-5,2.6948325557163265E-6,0.0,0.0,0.0,1.8832391713747646E-5,7.280669821623589E-6,0.0,0.0,5.378512841199408E-6]                                      |\n",
      "|0          |0.0       |[0.9703427645684432,0.0,6.208798176670569E-4,0.014817656710099882,0.012784201726440436,2.046956562649673E-4,1.4696828269356766E-5,1.423043029453023E-4,0.0,0.0,2.2393629275535028E-4,7.158982962352715E-5,4.603286663941044E-4,0.0,3.1694560109668144E-4]  |\n",
      "|0          |0.0       |[0.9703830106114293,0.0,6.432511823203008E-4,0.014817656710099885,0.01275915476338471,2.0469565626496733E-4,1.4696828269356768E-5,1.423043029453023E-4,0.0,0.0,1.863658481717561E-4,7.158982962352717E-5,4.603286663941045E-4,0.0,3.169456010966815E-4]    |\n",
      "+-----------+----------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Defining Random Forest model\n",
    "# -----------------------------\n",
    "rf = RandomForestClassifier(\n",
    "    featuresCol=\"scaled_features\",\n",
    "    labelCol=\"label_index\",\n",
    "    numTrees=50,            # number of trees in the forest\n",
    "    maxDepth=10,            # maximum depth of each tree\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Training the model\n",
    "# -----------------------------\n",
    "rf_model = rf.fit(train_df)\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Predicting on test data\n",
    "# -----------------------------\n",
    "rf_predictions = rf_model.transform(test_df)\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Evaluating the Accuracy\n",
    "# -----------------------------\n",
    "multi_evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label_index\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"accuracy\"\n",
    ")\n",
    "rf_accuracy = multi_evaluator.evaluate(rf_predictions)\n",
    "print(f\"✅ Random Forest Test Accuracy: {rf_accuracy:.4f}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Precision, Recall, F1, ROC-AUC\n",
    "# -----------------------------\n",
    "binary_evaluator = BinaryClassificationEvaluator(\n",
    "    labelCol=\"label_index\",\n",
    "    rawPredictionCol=\"prediction\",\n",
    "    metricName=\"areaUnderROC\"\n",
    ")\n",
    "roc_auc = binary_evaluator.evaluate(rf_predictions)\n",
    "precision = MulticlassClassificationEvaluator(labelCol=\"label_index\", predictionCol=\"prediction\", metricName=\"weightedPrecision\").evaluate(rf_predictions)\n",
    "recall = MulticlassClassificationEvaluator(labelCol=\"label_index\", predictionCol=\"prediction\", metricName=\"weightedRecall\").evaluate(rf_predictions)\n",
    "f1 = MulticlassClassificationEvaluator(labelCol=\"label_index\", predictionCol=\"prediction\", metricName=\"f1\").evaluate(rf_predictions)\n",
    "\n",
    "print(f\"ROC-AUC: {roc_auc:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")\n",
    "\n",
    "# showing some predictions\n",
    "rf_predictions.select(\"label_index\", \"prediction\", \"probability\").show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d542d40",
   "metadata": {},
   "source": [
    "IMPLEMENTING DECISION TREE ON THE SAMPLE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2a271e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Decision Tree Test Accuracy: 0.9960\n",
      "Precision: 0.9957, Recall: 0.9960, F1-score: 0.9958\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Initialize Decision Tree\n",
    "dt = DecisionTreeClassifier(\n",
    "    labelCol=\"label_index\",\n",
    "    featuresCol=\"scaled_features\",\n",
    "    maxDepth=10,        # maximum depth of the tree\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Training the model\n",
    "dt_model = dt.fit(train_df)\n",
    "\n",
    "# Predictions\n",
    "df_dt_preds = dt_model.transform(test_df)\n",
    "\n",
    "# Evaluation\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label_index\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"accuracy\"\n",
    ")\n",
    "\n",
    "accuracy = evaluator.evaluate(df_dt_preds)\n",
    "print(f\"✅ Decision Tree Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Precision, Recall, F1\n",
    "precision = evaluator.setMetricName(\"weightedPrecision\").evaluate(df_dt_preds)\n",
    "recall = evaluator.setMetricName(\"weightedRecall\").evaluate(df_dt_preds)\n",
    "f1 = evaluator.setMetricName(\"f1\").evaluate(df_dt_preds)\n",
    "print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5febc9",
   "metadata": {},
   "source": [
    "IMPLEMENTING NEURAL NETWORK ON THE SAMPLE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d2ff37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Neural Network Test Accuracy: 0.9737\n",
      "Precision: 0.9705\n",
      "Recall: 0.9737\n",
      "F1-score: 0.9719\n",
      "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------+----------+\n",
      "|scaled_features                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |label_index|prediction|\n",
      "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------+----------+\n",
      "|(68,[1,2,14,15,16,17,18,19,20,21,22,32,52,56,57],[5.992795318270895E-4,0.005335661157811919,0.0014912932387407011,0.0014467716292693672,8.243818410972506E-4,6.779013502111667E-7,6.006705128190732E-4,7.057382447741507E-4,0.0012076428287339043,8.220420975507104E-4,2.3278994584699821E-7,8.012292729046973E-4,0.005335661157811919,-6.974120374295814E-5,-1.1824687434333851E-4])                                                                                                                     |0          |0.0       |\n",
      "|(68,[1,2,14,15,16,17,18,19,20,21,22,32,52,56,57,60,62,63,64,66,67],[0.945225824468369,0.005335661157811919,2.35140445208265,2.2868876210907265,1.300106256045059,6.779013502111667E-7,0.9471103881221007,1.1127764866474226,1.908900741387402,1.2964163212712057,2.3278994584699821E-7,5.079847503356082E-7,0.005335661157811919,-6.974120374295814E-5,-1.1824687434333851E-4,3.0835649012666367E-6,1.9496503291642438E-6,3.4656502308085554E-6,1.3457424568055765,1.3050496875342608,1.3611021614049517])|0          |0.0       |\n",
      "|(68,[1,2,14,15,16,17,18,19,20,21,22,32,52,56,57,60,62,63,64,66,67],[0.946699954653511,0.005335661157811919,2.35140445208265,2.2868876210907265,1.304194640498031,6.779013502111667E-7,0.9500887226759438,1.1127764866474226,1.908900741387402,1.3004931021557062,2.3278994584699821E-7,5.071937538484018E-7,0.005335661157811919,-6.974120374295814E-5,-1.1824687434333851E-4,3.0835649012666367E-6,1.9496503291642438E-6,3.4656502308085554E-6,1.349974351323833,1.3091536173692742,1.365382356881068])  |0          |0.0       |\n",
      "|(68,[1,2,14,15,16,18,19,20,21,32,52,56,57,60,61,62,63,64,65,66,67],[3.186842442445421,0.1574020041554516,0.20334316991517923,0.26189910820188156,0.5028712877155417,3.1868179726120998,0.09622993526339109,0.21861126764804734,0.5014440487935795,4.4447534541225616E-6,0.1574020041554516,-6.974120374295814E-5,-1.1824687434333851E-4,5.5765430967971525,8.643718722424964,7.8709986571549955,1.7328251154042777E-6,0.31433903617785686,0.5009607557189405,0.5047833697066479,0.21401024462731238])     |0          |0.0       |\n",
      "|(68,[1,2,14,15,16,18,19,20,21,32,52,56,57,60,61,62,63,64,65,66,67],[3.3133724947669916,0.3895032645202701,0.08500258486508125,0.18193694331240434,0.4129268297501602,3.335734700304254,0.040226545313519615,0.1518656023023827,0.4117548693345653,1.057885952215293E-5,0.3895032645202701,-6.974120374295814E-5,-1.1824687434333851E-4,8.889382611841343,15.03908399263535,15.304755083939314,7.970995530859677E-5,0.3352431509640398,0.391386217260717,0.41449691333635325,0.2143852753549297])          |0          |0.0       |\n",
      "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------+----------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Defining the network layers\n",
    "# -----------------------------\n",
    "# Input layer = 68 (number of features)\n",
    "# Hidden layers = we can try [128, 64] or [100, 50] as starting point\n",
    "# Output layer = number of classes\n",
    "layers = [68, 128, 64, 15]\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Defining the model\n",
    "# -----------------------------\n",
    "mlp = MultilayerPerceptronClassifier(\n",
    "    featuresCol=\"scaled_features\",\n",
    "    labelCol=\"label_index\",\n",
    "    maxIter=100,\n",
    "    layers=layers,\n",
    "    blockSize=128,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Training the model\n",
    "# -----------------------------\n",
    "mlp_model = mlp.fit(train_df)\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Making the predictions\n",
    "# -----------------------------\n",
    "df_mlp_preds = mlp_model.transform(test_df)\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Evaluating\n",
    "# -----------------------------\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label_index\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"accuracy\"\n",
    ")\n",
    "accuracy = evaluator.evaluate(df_mlp_preds)\n",
    "precision = evaluator.evaluate(df_mlp_preds, {evaluator.metricName: \"weightedPrecision\"})\n",
    "recall = evaluator.evaluate(df_mlp_preds, {evaluator.metricName: \"weightedRecall\"})\n",
    "f1 = evaluator.evaluate(df_mlp_preds, {evaluator.metricName: \"f1\"})\n",
    "\n",
    "print(f\"✅ Neural Network Test Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")\n",
    "\n",
    "# Optional: Show predictions\n",
    "df_mlp_preds.select(\"scaled_features\", \"label_index\", \"prediction\").show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e815c5",
   "metadata": {},
   "source": [
    "IMPLEMENTING K-MEANS ON THE SAMPLE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e3b66c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ KMeans model training complete\n",
      "+----------+-----------+------+\n",
      "|prediction|label_index|count |\n",
      "+----------+-----------+------+\n",
      "|0         |0          |107235|\n",
      "|0         |10         |31471 |\n",
      "|0         |7          |793   |\n",
      "|0         |3          |659   |\n",
      "|0         |11         |615   |\n",
      "|0         |4          |459   |\n",
      "|0         |6          |406   |\n",
      "|0         |2          |393   |\n",
      "|0         |12         |272   |\n",
      "|0         |1          |230   |\n",
      "|0         |14         |133   |\n",
      "|0         |5          |34    |\n",
      "|0         |13         |3     |\n",
      "|0         |9          |2     |\n",
      "|1         |0          |197425|\n",
      "+----------+-----------+------+\n",
      "only showing top 15 rows\n",
      "✅ Cluster → Label mapping created\n",
      "+----------+-----------+------+---+\n",
      "|prediction|label_index| count| rn|\n",
      "+----------+-----------+------+---+\n",
      "|         0|          0|107235|  1|\n",
      "|         1|          0|197425|  1|\n",
      "|         2|          0|    73|  1|\n",
      "|         3|          0|  4701|  1|\n",
      "|         4|          2|  2411|  1|\n",
      "|         5|          0|     6|  1|\n",
      "|         6|          0|   912|  1|\n",
      "|         7|          4|  8824|  1|\n",
      "|         8|          0|     1|  1|\n",
      "|         9|          0|   136|  1|\n",
      "|        10|          0|  2977|  1|\n",
      "|        11|          4| 21183|  1|\n",
      "|        12|          0|127748|  1|\n",
      "|        13|          0|   897|  1|\n",
      "|        14|          0|  5453|  1|\n",
      "+----------+-----------+------+---+\n",
      "\n",
      "✅ Cluster → Class assignment complete (no ambiguity)\n",
      "\n",
      "===== KMeans (Cluster-Mapped) Classification Report =====\n",
      "✅ Accuracy:  0.8460\n",
      "Precision:   0.7796\n",
      "Recall:      0.8460\n",
      "F1 Score:    0.8008\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.sql.functions import col, count, desc\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Train KMeans model\n",
    "# -----------------------------\n",
    "k = 15   # number of attack types (clusters)\n",
    "kmeans = KMeans(\n",
    "    featuresCol=\"scaled_features\",\n",
    "    k=k,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "kmeans_model = kmeans.fit(train_df)\n",
    "print(\"✅ KMeans model training complete\")\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Assign clusters on training set\n",
    "# -----------------------------\n",
    "df_kmeans_train = kmeans_model.transform(train_df)\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Map clusters → real labels using majority vote\n",
    "# -----------------------------\n",
    "cluster_map = (\n",
    "    df_kmeans_train.groupBy(\"prediction\", \"label_index\")\n",
    "    .agg(count(\"*\").alias(\"count\"))\n",
    "    .orderBy(\"prediction\", desc(\"count\"))\n",
    ")\n",
    "\n",
    "cluster_map.show(15, truncate=False)\n",
    "\n",
    "# Extract dominant label per cluster\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import row_number\n",
    "\n",
    "window = Window.partitionBy(\"prediction\").orderBy(desc(\"count\"))\n",
    "cluster_label_map = cluster_map.withColumn(\"rn\", row_number().over(window)).filter(col(\"rn\") == 1)\n",
    "\n",
    "print(\"✅ Cluster → Label mapping created\")\n",
    "cluster_label_map.show()\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Test on full test_df\n",
    "# -----------------------------\n",
    "df_kmeans_test = kmeans_model.transform(test_df)\n",
    "\n",
    "# ✅ Fix: rename label column before joining to avoid ambiguity\n",
    "cluster_label_map_fixed = cluster_label_map.withColumnRenamed(\"label_index\", \"mapped_label\")\n",
    "\n",
    "predicted_df = df_kmeans_test.join(\n",
    "    cluster_label_map_fixed,\n",
    "    on=\"prediction\",\n",
    "    how=\"left\"\n",
    ").select(\n",
    "    \"scaled_features\",\n",
    "    df_kmeans_test[\"label_index\"].alias(\"true_label\"),\n",
    "    col(\"mapped_label\").alias(\"predicted_label\")\n",
    ")\n",
    "\n",
    "print(\"✅ Cluster → Class assignment complete (no ambiguity)\")\n",
    "\n",
    "# ✅ Fix: cast to double to avoid IllegalArgumentException\n",
    "predicted_df_fixed = predicted_df.withColumn(\n",
    "    \"true_label\", col(\"true_label\").cast(\"double\")\n",
    ").withColumn(\n",
    "    \"predicted_label\", col(\"predicted_label\").cast(\"double\")\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Evaluate mapping accuracy\n",
    "# -----------------------------\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"true_label\",\n",
    "    predictionCol=\"predicted_label\"\n",
    ")\n",
    "\n",
    "accuracy = evaluator.evaluate(predicted_df_fixed, {evaluator.metricName: \"accuracy\"})\n",
    "precision = evaluator.evaluate(predicted_df_fixed, {evaluator.metricName: \"weightedPrecision\"})\n",
    "recall = evaluator.evaluate(predicted_df_fixed, {evaluator.metricName: \"weightedRecall\"})\n",
    "f1 = evaluator.evaluate(predicted_df_fixed, {evaluator.metricName: \"f1\"})\n",
    "\n",
    "print(\"\\n===== KMeans (Cluster-Mapped) Classification Report =====\")\n",
    "print(f\"✅ Accuracy:  {accuracy:.4f}\")\n",
    "print(f\"Precision:   {precision:.4f}\")\n",
    "print(f\"Recall:      {recall:.4f}\")\n",
    "print(f\"F1 Score:    {f1:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a6f732",
   "metadata": {},
   "source": [
    "IMPLEMENTING BISECTING K-MEANS ON THE SAMPLE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e2b93cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Bisecting KMeans model training complete\n",
      "+----------+-----------+------+\n",
      "|prediction|label_index|count |\n",
      "+----------+-----------+------+\n",
      "|0         |0          |30924 |\n",
      "|0         |10         |30902 |\n",
      "|0         |4          |1619  |\n",
      "|0         |7          |793   |\n",
      "|0         |6          |389   |\n",
      "|0         |12         |244   |\n",
      "|0         |1          |222   |\n",
      "|0         |14         |130   |\n",
      "|0         |5          |15    |\n",
      "|0         |11         |6     |\n",
      "|0         |2          |3     |\n",
      "|1         |0          |195614|\n",
      "|1         |5          |110   |\n",
      "|1         |2          |13    |\n",
      "|2         |0          |50709 |\n",
      "|2         |4          |13506 |\n",
      "|2         |2          |9191  |\n",
      "|2         |10         |843   |\n",
      "|2         |3          |279   |\n",
      "|2         |1          |4     |\n",
      "+----------+-----------+------+\n",
      "only showing top 20 rows\n",
      "✅ Cluster → Label mapping created\n",
      "✅ Cluster → Class assignment complete\n",
      "\n",
      "===== Bisecting KMeans Classification Report =====\n",
      "✅ Accuracy:  0.8598\n",
      "Precision:   0.7956\n",
      "Recall:      0.8598\n",
      "F1 Score:    0.8204\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.clustering import BisectingKMeans\n",
    "from pyspark.sql.functions import col, count, desc\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import row_number\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Training the Bisecting KMeans\n",
    "# -----------------------------\n",
    "bkmeans = BisectingKMeans(\n",
    "    featuresCol=\"scaled_features\",\n",
    "    k=15,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "bk_model = bkmeans.fit(train_df)\n",
    "print(\"✅ Bisecting KMeans model training complete\")\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Assigning clusters on training set\n",
    "# -----------------------------\n",
    "df_bk_train = bk_model.transform(train_df)\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Cluster → Label mapping using majority voting\n",
    "# -----------------------------\n",
    "cluster_map = (\n",
    "    df_bk_train.groupBy(\"prediction\", \"label_index\")\n",
    "    .agg(count(\"*\").alias(\"count\"))\n",
    "    .orderBy(\"prediction\", desc(\"count\"))\n",
    ")\n",
    "\n",
    "cluster_map.show(20, truncate=False)\n",
    "\n",
    "# Picking the dominant class for each cluster\n",
    "window = Window.partitionBy(\"prediction\").orderBy(desc(\"count\"))\n",
    "cluster_label_map = cluster_map.withColumn(\"rn\", row_number().over(window)).filter(col(\"rn\") == 1)\n",
    "\n",
    "cluster_label_map_fixed = cluster_label_map.withColumnRenamed(\"label_index\", \"mapped_label\")\n",
    "print(\"✅ Cluster → Label mapping created\")\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Assigning the predicted labels to test_df\n",
    "# -----------------------------\n",
    "df_bk_test = bk_model.transform(test_df)\n",
    "\n",
    "predicted_df = df_bk_test.join(\n",
    "    cluster_label_map_fixed, \n",
    "    on=\"prediction\", \n",
    "    how=\"left\"\n",
    ").select(\n",
    "    \"scaled_features\",\n",
    "    df_bk_test[\"label_index\"].alias(\"true_label\"),\n",
    "    col(\"mapped_label\").alias(\"predicted_label\")\n",
    ")\n",
    "\n",
    "# Casting to double (Spark evaluator requirement)\n",
    "predicted_df = predicted_df.withColumn(\"true_label\", col(\"true_label\").cast(\"double\")) \\\n",
    "                           .withColumn(\"predicted_label\", col(\"predicted_label\").cast(\"double\"))\n",
    "\n",
    "print(\"✅ Cluster → Class assignment complete\")\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Evaluation of the results\n",
    "# -----------------------------\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"true_label\", predictionCol=\"predicted_label\")\n",
    "\n",
    "accuracy = evaluator.evaluate(predicted_df, {evaluator.metricName: \"accuracy\"})\n",
    "precision = evaluator.evaluate(predicted_df, {evaluator.metricName: \"weightedPrecision\"})\n",
    "recall = evaluator.evaluate(predicted_df, {evaluator.metricName: \"weightedRecall\"})\n",
    "f1 = evaluator.evaluate(predicted_df, {evaluator.metricName: \"f1\"})\n",
    "\n",
    "print(\"\\n===== Bisecting KMeans Classification Report =====\")\n",
    "print(f\"✅ Accuracy:  {accuracy:.4f}\")\n",
    "print(f\"Precision:   {precision:.4f}\")\n",
    "print(f\"Recall:      {recall:.4f}\")\n",
    "print(f\"F1 Score:    {f1:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
